---
title: Lecture 6 - Deep Learning IV
layout: orf525
date: 2017-02-23
---

# Backpropagation

Last time

- Introduced gradient descent and stochastic gradient descent
- Need to calculate the gradient
- Reduced to:

	$$
	\frac{\partial f_w}{\partial w}
	$$

	Where $f_w(x) = \sigma(w^{(l)} \sigma(w^{(l-1)})... \sigma(w^{(1)}x)...)$

### Explore simple case

#### Notation:

$$
z^{(k)} = \sigma(w^{(k-1)} \sigma(w^{(k-2)})... \sigma(w^{(1)}x)...)
$$

$$
\frac{\partial f}{\partial w_{jk}^{(l)}} = \frac{\partial f}{\partial z_k^{(l)}} \frac{\partial z_k^{(l)}}{\partial w_{jk}^{(l)}}
$$

<img src="{{ site.url }}/images/orf525/nn-notation.png" style="width: 500px;"/>

#### Idea: chain rule for $z^{(l)}$

$$
\delta_i^{(l)} 
= \frac{\partial f}{\partial z_i^{(l)}}
= \sum_{k} \frac{\partial f}{\partial z_k^{(l+1)}} \frac{\partial z_k^{(l+1)}}{\partial z_i^{(l)}}
$$

$$
= \sum_k \delta_k^{(l+1)} w_{ik}^{(l+1)} \sigma^{\prime}(z_i^{(l)})
$$

You should be able to tell that this is an **iterative formula**.

$$
\frac{\partial f}{\partial w_{ji}^{(l)}}
=
\frac{\partial f}{\partial z_i^{(l)}}
\frac{\partial z_i^{(l)}}{\partial w_{ji}^{(l)}}
=
\delta_i^{(l)} \cdot \sigma(z_j^{(l)})
$$

<span style="color: red;">Shouldn't that be $\sigma^{\prime}(z_j^{(l)})$?</span>

### Algorithm

Let $L$ be the number of layers in the network.

**1. Initial**

$$
\delta_i^{(L)} = \sigma^{\prime}(z_i^{L})
$$

This is the derivative of the output layer

**2. Iteratively**

$$
\delta_i^{(l)} = \sum \delta_k^{(l+1)} w_{ik}^{(l+1)} \sigma^{\prime}(z_i^{(l)})
$$

$$
\frac{\partial f}{\partial w_{ji}^{(l)}} = \delta_i^{(l)} \sigma(z_j^{(l)})
$$

### Rmarks

The sigmoid activation function (no longer recommended):

$$
\sigma(z) = \frac{1}{1 + e^{-z}}
$$

1. $\sigma^{\prime}(z) \rightarrow 0$ as $z \rightarrow \pm \infty$

	- Called "oversaturation"
	- You can oversaturate the network with a strong signal
	- Algorithm may get stuck

2. Exponential function is still **expensive** to compute

3. ReLU activation function:

	$$
	\sigma(z) = \begin{cases} z & z \geq 0 \\ 0 & z < 0 \end{cases}
	$$

	- Not saturated
	- Derivative is easier to calculate

4. Leaky ReLU

	$$
	\sigma(z) = \begin{cases} z & z \geq 0 \\ \alpha z & z < 0 \end{cases}
	$$

	- For example, $\alpha = 0.01$.
	
	<img src="{{ site.url }}/images/orf525/leaky-relu.png" style="width: 300px;"/>

# Dropout

- It is very easy to overfit in training
- Dropout is to avoid overfitting
- Each iteration, dropout a few randomly selected neurons

<img src="{{ site.url }}/images/orf525/dropout.png" style="width: 300px;"/>

### Intuition

- Imagine a neural network that classifies cats

<img src="{{ site.url }}/images/orf525/cat-labeling-nn.png" style="width: 200px;"/>

- It might overfit by just picking $\\{ \text{ear}, \text{tail}, \text{furry} \\}$
- Dropout will prevent this and encourage redundancy. The network might be forced to learn "cat" without some of those features some time
- Avoids overfitting

# Recurrent neural network

Previous applications: Input $\\{ X_i\\}_{i=1}^n$ images are independent samples

Now: Input is $\\{X_t\\}_{t=1}^{T}$ where data is **time-dependent**

For example: sentences, videos, audio.

### Example

We want to predict the next letter in a word:

$$
\text{"hell"} \stackrel{\text{Predict}}{\rightarrow} \text{"o"}
$$

First embed the letters:

$$
\text{"h"} = (1, 0, 0, 0)
$$

$$
\text{"e"} = (0, 1, 0, 0)
$$

$$
\text{"l"} = (0, 0, 1, 0)
$$

<img src="{{ site.url }}/images/orf525/rnn-example.png" style="width: 300px;"/>

Therefore:

$$
y_1 = \sigma(u^{\top} x_1 + \beta_0)
$$

$$
y_2 = \sigma(u^{\top} x_2 + w(u^{\top} x_1 + \beta_0))
$$

Where $w(u^{\top} x_1 + \beta_0)$ is the weighted history.


### Training

Train by minimizing the loss:

$$
\min_{u, w, \beta_0} |\text{"e"} - y_1|^2 + |\text{"l"} - y_1|^2 + |\text{"l"} - y_1|^2 + |\text{"o"} - y_1|^2
$$

<span style="color: red;">Why do we not include "h"?</span>

> **Definition.** A neural unit is **recurrent** if it can be written as:
>
> $$
> \sigma(w s_{t-1} + u y_t + \beta_0)
> $$
>
> Where $s_{t-1}$ is the output from $t-1$ and $y_t$ is the output from the current time.

A neural network with recurrent units is **recurrent neural network**.

(Input is just output of first node.)

### Example: many-to-many

Applications

- Letter prediction
- Fake papers

<img src="{{ site.url }}/images/orf525/rnn-many-to-many.png" style="width: 300px;"/>

### Example: many-to-one

Applications

- Video classification

<img src="{{ site.url }}/images/orf525/rnn-many-to-one.png" style="width: 300px;"/>

### Example: many-to-many delayed

Applications

- Machine translation: you do not want to translate word-by-word but you need to see the full translation

<img src="{{ site.url }}/images/orf525/rnn-many-to-many-delayed.png" style="width: 600px;"/>

# Case study of captioning

Auto-captioning: $\text{Image} \stackrel{\text{Predict}}{\rightarrow} \text{Caption}$

What we will do:

- CNN to extract image features
- RNN to caption based

$$
\text{Image} \rightarrow \text{CNN} \rightarrow \text{Features} \rightarrow \text{RNN} \rightarrow \text{Caption}
$$

Example image

A dog [Snoopy] laying on a house with a bird [Woodstock] on his belly.

<img src="{{ site.url }}/images/orf525/snoopy.png" style="width: 200px;"/>

Task decomposition:

- **Localization:** Identify things in boxes.
- **Classification:** Identify objects.
- **Captioning:** Generate a caption from objects.

### Step 1. Train a classification model to just recognize objects:

<img src="{{ site.url }}/images/orf525/image-captioning-cnn.png" style="width: 600px;"/>


### Step 2. Build box coordinate regression head

<img src="{{ site.url }}/images/orf525/image-captioning-nn-diagram.png" style="width: 600px;"/>

A single data point is by convention: $(x, y, h, w)$

<img src="{{ site.url }}/images/orf525/object-detection.png" style="width: 200px;"/>

### Step 3. Train the regression head only (with classification head as the initialization)

The convolutional layers and pooling are fixed.

### Step 4. Localization

- Use a sliding window to identify the coordinates
- Very position and size to make classification as accurate as possible

<img src="{{ site.url }}/images/orf525/object-location-probabilities.png" style="width: 300px;"/>

<img src="{{ site.url }}/images/orf525/image-captioning-nn-output.png" style="width: 500px;"/>

Can try with different size windows.

Average all coordinates from score matrices

### Step 5. Caption generation

Connect with RNN

<img src="{{ site.url }}/images/orf525/image-captioning-nn.png" style="width: 650px;"/>

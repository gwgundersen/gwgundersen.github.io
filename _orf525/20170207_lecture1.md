---
title: Lecture 1
layout: orf525
date: 2017-02-07
---

# Lecture 1

### Grading

- Participation: 20%
- Midterm: 10%
- Project: 20%
- Homework: 50%

Asking questions is important. Otherwise, you could just read a book.

### Themes

- **What is data science?** Discovery from data.
- **What is data analytics?** Making optimal decisions.
- **What is artificial intelligence?** More complex decision making (?)

### Model decision making

- We want to reinforce this kind of thinking: _data_ $\rightarrow$ _model_ $\rightarrow$ _decision_ $\rightarrow$ _value_
- Two kinds of plans
    - Business plan
    - Scientific plan
- Pipeline
    1. **Raw data** 
        - Text, images, numerical values
    2. **Feature engineering**
        - Time intensive
        - A.K.A. _munging_, _data wrangling_
        - Liu estimated 80% of a project might be this step
        - Not what this course is about though
    3. **Analytic data**
        - Process data
        - Typically a data matrix
    4. **Statistics / Machine learning**
        - Inference / prediction
        - Examples: find underlying pattern in data / predict price of stock
    5. **Knowledge / Intelligence**
- Need to operate under uncertainty and incompleteness

### Advanced perspective

- Statistics
    - Model-based approach
    - Likelihood estimation (sample space)
    - Maximum entropy (population space)
- Machine learning
    - Model-free
    - Empirical Risk Minimization (sample space)
        - Need a good enough loss function to minimize
    - Risk minimization (population space)
- Regularization

### Topics

\* _Parametric and nonparametric methods_

1. Fundamental principles\*
2. Regression analysis\*
   - Especially high-dimensional regression analysis\*
3. Classification\*
4. Graphical models\*
5. Clustering\*
6. Deep learning
    - Began around roughly 2008
    - Liu wants to catch up

## I. Fundamental principles of data analysis

1. **Concentration principle**

    - Data = signal + noise

    $$
    X_1, ..., X_n = \theta + \epsilon_1, ..., \epsilon_n \sim N(0, \sigma^2)
    $$
    
    - <span style="color: red;">QUESTION: Why is it just $\theta$ and not $\theta_1, ..., \theta_n$</span>
    - What this means is that we have some signal $\theta$ and some noise $\epsilon$ which is drawn from a Gaussian.
    - Concentration phenomenon---similar to the law of large numbers:

    $$
    \frac{1}{n} \sum_{i=1}^{n} X_i \xrightarrow{P} \frac{\mathbb{E} X}{\theta}
    $$

    - As $n \rightarrow \infty$.
    - <span style="color: red;">QUESTION: Is the above equation correct? I do not understand the right-hand term.</span>
    - In words, we sum out the noise.

2. **Parsimonious principle**

    - Intuition: if two explanations are _equally good_, prefer the simpler one.
    - Formally, we express this as _regularization_, i.e. we want to prevent overfitting.
    - This is not a universal rule. It is especially good for small sample sizes with noisy data.
    - Remark: we always use _wrong_ model to control variance. (GWG: I believe this means that our model makes simplifying assumptions to avoid overfitting.)

### Basic concepts

1. **Sample space**: All possible outcomes of a statistical experiment.

2. **Random sample**: $\vec{X_1}, ..., \vec{X_n} \stackrel{iid}{\sim} p(X)$ where $p(X)$ is the density of $X$. 

3. **Realizations** or **observed values**: $\vec{x_1}, ..., \vec{x_n}$.

    - <span style="color: red;">CONFIRM: I believe this is distinct from the _values_ that a random variable may take. So we may denote $P(X=1)$ as the probability that the random variable $X$ is 1, but that is distinct from observing 1.</span>

4. **Notation**: $X_1, ..., X_n = X_{1:n}$

5. **Statistic**: Any measurable function of random variables $X_{1:n}$

6. **CDF (cumulative distribution function)**: $F(x) = P(X \leq x)$

    - GWG: In words, ["The probability that $X$ will take a value less than or equal to $x$."](https://en.wikipedia.org/wiki/Cumulative_distribution_function)

7. **PDF (probability density function)**: $P(X) = \frac{\partial}{\partial x} F(x)$

    - Can also be PMF (probability mass function)
    - Remark: $p_{\theta}(x)$ is parameterized by $\theta$

8. **Law of large numbers**: Central Limit Theorem:

    - From [Wikipedia](https://en.wikipedia.org/wiki/Central_limit_theorem):

        > In probability theory, the central limit theorem (CLT) establishes that, for the most commonly studied scenarios, when independent random variables are added, their sum tends toward a normal distribution (commonly known as a bell curve) even if the original variables themselves are not normally distributed.

9. **Statistical model**: Set of probability distributions indexed by a parameter set $\theta$.

    $$P: \{ P_{\theta}, \theta \in \Theta \}$$

10. **Parametric model**: If there exists a finite-dimensional $\Theta$ to index $P$.

    - <span style="color: red;">QUESTION: Shouldn't we index $P$ by $\theta$?</span>

    _Example_:

    $$
    P = \int P_{\mu,\sigma^2}(x) = \frac{1}{\sqrt{2 \pi \sigma^2}} e^{\frac{-(x-\mu)}{2 \sigma^2}}
    $$

    Where $\mu \in \mathbb{R}$, $\sigma^2 > 0$

    - GWG: Observe that we are parameterizing the Gaussian distribution its two parameters, $\mu$ the mean and $\sigma^2$ the variance.

11. **Nonparametric model**: If there does not exist a finite-dimensional representation.

    _Example_: $P: \int p(x)$ is continuous and $\int p(t)dt < \infty$

    cf. [Sobolev space](https://en.wikipedia.org/wiki/Sobolev_space).

12. **Point estimation**

    $$
    X_1, ..., X_n \sim P_{\theta}(x)
    $$

    Make a simple best guess of value $\theta$, denoted $\hat{\theta}$.

    $$
    \hat{\theta}_n = f(X_1, ... X_n) 
    $$

    $\hat{\theta_n} \xrightarrow{P} \theta$ as $n \rightarrow \infty$

13. **Consistent estimator**

    - $\theta_n \xrightarrow{P} \theta$ as $n \rightarrow \infty$
    - In words, our estimate goes to the true value with more samples.

14. **[Unbiased estimator](https://en.wikipedia.org/wiki/Bias_of_an_estimator)**

    - Biased (definition):
    
        $$
        bias(\hat{\theta_n}) = \mathbb{E}\hat{\theta_n} - \theta
        $$

    - If bias($\hat{\theta_n}$) $\rightarrow \theta$ unbiased
        - <span style="color: red;">QUESTION: As $n \rightarrow \infty$ right?</span>
    - Consistency vs. bias
        - Unbiased but inconsistent
            - $\hat{\theta_n} = X_1$
            - <span style="color: red;">QUESTION: Unbiased because it does not deviate predictably. But inconsistent.</span>
        - Biased but consistent
            - $\hat{\theta_n} = \frac{1}{n+1} \sum_{i=1}^{n} X_i$
            - Biased because the estimate average is always off because of the $+1$, but consistent, i.e. with enough samples the off-by-one error is negligible.

15. **Likelihood**
    
    - (This point is subtle)
    - A measure of how likely the parameters are given the data.
    - The likelihood function is related to a random sample $X_i$:

    $$
    L(X_i, \theta) = P_{\theta}(X_i)
    $$

    - The likelihood is a random quantity. So the whole function is random.
    - <span style="color: red;">QUESTION: Shouldn't this be $L(\theta | X_i) = P_{\theta}(X_i)$</span>

16. **Joint likelihood**

    - The joint likelihood of a parameter $\theta$ w.r.t. the entire dataset is defined as:

    $$
    L_n(\theta) = P_{\theta}(X_1,...,X_n)
    $$

    - <span style="color: red;">QUESTION: Shouldn't it be: $L_n(\theta) = P_{\theta}(\theta | X_1,...,X_n)$</span>



17. **Joint log likelihood**

    $$
    l_n(\theta) = \log[L_n(\theta)]
    $$

18. **Maximum likelihood estimator**

    - $\hat{\theta_n}$ is a MLE if $L_n(\hat{\theta_n}) \geq L_n({\theta_n})$ for all $\theta \in \Theta$.
    - If $L_n(\theta)$ has a unique maximizer, then:
    
    $$
    \theta_n = \arg\max_{\theta \in \Theta} L_n(\theta)
    $$

    - _Example_:
        - $X_1,...,X_n \stackrel{iid}{\sim} N(u, \sigma^2)$
        - $\hat{u} = \frac{1}{n} \sum_{i=1}^{n} X_i$
        - $\hat{\sigma^2} = \frac{1}{n} \sum_{i=1}^{n} X_i^2 - (\frac{1}{n} \sum_{i=1}^{n} X_i)^2$
            - <span style="color: red;">QUESTION: I do not understand the estimate for $\sigma$.</span>

    - _Theorem_: MLE is an asymptotically normal and "efficient".
    
        $$
        \sqrt{n}(\hat{\theta_n} - \theta) \xrightarrow{D} N(0, I^{-1}(\theta))
        $$
        
        - Where $D$ is the _converging distribution_.
        - In addition, if $\hat{\theta}_n$ is an unbiased estimator of $\theta$, then:
        
        $$
        var(\hat{\theta_n}) \geq \frac{I^{-1}(\theta)}{n}
        $$

## II. Regression

> **Regression**: The art of summarizing the relationship between two variables.

- Notation: $Y$ is the _response_, $X$ is the _predictor_, _feature_, or _covariates_.
- Data: $(Y_1, X_1), ..., (Y_n, X_n) \sim P$
- Goal: Find a mapping $f$ such that $f(X)$ is "close" to $Y$. 
- What is "closeness" between two random functions? Measure using _loss functions_.

#### Loss functions

- $L1$ loss:

    $$
    l(f(x), y) = |f(x) - y|
    $$

    - A measure of **absolute difference**

- $L2$ loss:

    $$
    l(f(x), y) = |f(x) - y|^2
    $$

    - A measure of the squared difference.

- Then take expectation:

    $$
    R(f) = \mathbb{E} l(f(x), y) = EM = f(x)^2
    $$

    - $R$ stands for "risk". We want to minimize the expected loss, which is the risk.

#### Theorem
    
If 

$$
f^* = \arg\min_f \mathbb{E} |Y - f(x)|^2
$$
    
Where $f^*$ is the regression function, then:

$$
f^*(x) = \mathbb{E}(Y|X=x)
$$

Estimate conditional mean.

#### Question

To minimize population risk $R(f)$, the expectation w.r.t. $P_{y,x}$ (unknown) is:

$$
R(f) = \frac{1}{n} \sum_{i=1}^{n}(Y_i - f(X_i))^2
$$

- Empirical risk minimization

$$
\hat{f} = \arg\min_f \hat{R}(f)
$$

#### Overfitting

- _Problem_: a trivial solution is: $\hat{f(x)} = Y_i$ for $x = X_i$.
- Basically, just mimic the data exactly.

> **Overfitting**: Phenomenon when a model is too flexible so that it fits noise in addition to the signal in the data.

- Solution to overfitting: **regularization**.

    - Intuition: shrink model space.
    - Introduce additional information or constraints to reduce the flexibility of the model.

- _Examples_
    
    $$
    \hat{f} = \arg\min_{f \in F} \frac{1}{n} \sum_{i=1}^{n} |Y_i - f(X_i)|^2
    $$

    - So constrain class of $F$ in the following ways:
        - Linear model regularization:
        
        $$
        f = \{f(x): f(x) = \beta^{\top} x \}
        $$

        - Polynomial regularization

        $$
        f = \{f(x): f(x) = poly(x) \}
        $$

        - Nonparametric regularization

        $$
        f = \{f(x): f(x) = \int f^{\prime \prime}(t)^2 dt \leq \infty \}
        $$

        - <span style="color: red;">QUESTION: Is this equation correct?</span>

#### Ordinary least squares

- From [Wikipedia](https://en.wikipedia.org/wiki/Ordinary_least_squares): 

    > ...ordinary least squares (OLS) or linear least squares is a method for estimating the unknown parameters in a linear regression model, with the goal of minimizing the sum of the squares of the differences between the observed responses in the given dataset and those predicted by a linear function of a set of explanatory variables (visually this is seen as the sum of the vertical distances between each data point in the set and the corresponding point on the regression line â€“ the smaller the differences, the better the model fits the data).

<span style="color: red;">CONFIRM: Check this against the lecture notes</span>

$$
(Y_1, \vec{X_1}), ..., (Y_n, \vec{X_n}) \sim P
$$

$$
\vec{X_i} = \begin{bmatrix}
    \textbf{X_1} \\
    ... \\
    \textbf{X_n}
\end{bmatrix}
$$

$$
\vec{Y_i} = \begin{bmatrix}
    Y_1 \\
    ... \\
    Y_n
\end{bmatrix}
$$

$$
\textbf{X} = \begin{bmatrix}
    X_{11} & ... & X_{1d} \\
    X_{21} & ... & X_{2d} \\
    ... & ... & ... \\
    X_{n1} & ... & X_{nd}
\end{bmatrix}
$$

<span style="color: red;">I'm fairly certain $d$ is the number of features, and $n$ is the number of samples.</span>

$$
\vec{Y} = \textbf{X} \vec{\beta} + \epsilon
$$

<img src="{{ site.url }}/images/orf525/ols.png" style="width: 100%;"/>

$$
\vec{\beta} = \arg \min_{\vec{\beta}} \|{\vec{Y} - \boldsymbol{X}\vec{\beta}}\|_2^2
$$

$$
\vec{\beta}^{\text{OLS}} = (\textbf{X}^{\top}\textbf{X})^{-1} \textbf{X}^{\top} \vec{Y}
$$

<div style="color: red;">
    <p>For a derivation see <a href='https://stats.stackexchange.com/questions/46151' target='_blank'>here</a>.</p>
    <p>A simple way to understand the derivation is to do it in two dimensions:</p>

    $$
    y = x \beta + \epsilon
    $$

    $$
    \epsilon = y - x \beta
    $$

    $$
    \epsilon^2 = (y - x \beta)(y - x \beta) = y^2 - 2 yx \beta + x^2 \beta^2
    $$

    $$
    \frac{\partial \epsilon^2}{\partial \beta} = - 2 yx + 2 \beta x^2
    $$

    Then solving for the minimum:

    $$
    0 = - 2 yx + 2 \beta x^2
    $$

    $$
    \beta = \frac{y}{x}
    $$

    <p>The key point is that $\vec{\beta}^{\text{OLS}}$ is a closed-form equation and has a solution provided that $\vec{X}^{\top} \vec{X}$ is invertible. Intuitively, a matrix $\vec{A}$ is not invertible when either (1) there are more features than samples or (2) the features are dependent.</p>.
</div>


---
title: Lecture 1 - Introduction
layout: orf309
date: 2017-02-06
---

# Lecture 1 - Introduction

## Admin

- Organizational stuff is on [Blackboard](https://blackboard.princeton.edu/)
- Homeworks
    - Due Friday at 5:00PM
    - In principle, there are no extensions; email Ramon if you have issues.
    - Collaboration is O.K., but you must write your own solutions
    - Nearly always 5 problems
- Office hours: **Blackboard** > **Contacts** has office hours for Ramon and AIs.

### Grading

- Homeworks (every week except midterm weeks) - 20%
- Midterms (2 at 20% each) - 40%
- Final - 40%

### Textbooks

- Required: none
- Alternative references
    - Bertsekas and Tsitsiklis, _Introduction to Probability_
        - Highly recommended
        - Only reason this book is not the course textbook is that the course covers more material
    - Ross
        - Will post exact title on Blackboard
        - Contains a "gazillion" examples

### Missing lectures

- 10 Feb, 13 Feb, 15 Feb
- Next week's homework will only have 3 problems


## Probability

Intro

- About randomness
- Touches almost every field in science and engineering
    - Quantum mechanics
    - Heredity
    - Randomized algorithms
    - Chemical mixtures
    - Statistics, data science, ML
    - Prime numbers
- Course goal: develop the foundations of the field

What does it mean to be random?

- What is _not_ random?
    - If you repeat an experiment with the same initial conditions and get the same result, it is not random.
    - We call this _deterministic_
- Truly random?
    - Throwing dice, flipping coins, throwing a piece of chalk at the same arc
    - We are bad at these tasks though, perhaps they are less random than they seem
    - Defining "random" was a major hurdle for probability theory; allows us to reason about something we cannot predict

Your intuition about randomness and probability is often wrong

- Here is a common notion of probability:

$$
    \text{probability} = \frac{\text{# favorable outcomes}}{\text{# total outcomes}}
$$

- Example
    - Flip two coins
    - What is the probability that head coin lands on heads, the other tails, i.e. $p(heads, tails)$
- Solution 1
    - Possible outcomes: {2 tails, 2 heads, 1 tails and 1 heads}
    - $probability = \frac{1}{3}$
- Solution 2
    - Possible outcomes: {heads heads, heads tails, tails heads, tails tails}
    - Above, we imply that order matters
    - $probability = \frac{2}{4} = \frac{1}{2}$
- At this point, Ramon asked the class which was the correct solution? Everyone who voted by raising their hands said that solution 2 was correct. He then observed that bothe solutions are valid; the problem is that our definition of probability is vague.
- He observed that Jean le Rond d'Alembert forcefully argued for solution #1.
- Upshot: in probability, is it really bad to rely on your intuition
- We want to reason reliably about probability and randomness.

### Probability theory

> A _mathematical_ description of random phenomena.

- Everything we say about probability will be logically extended fromaxioms.
- Next lecture: define those axioms.
- Nothing but common sense written down into mathematical language.
- But once we have firm definitions and logic, we do not need our intuition.

History

- Blaise Pascal and Fermat corresponded about probability. Pascal was trying to help a friend, who was a gambler, understand a problem.
- Andrey Kolmogorov (1933)
    - Set down axioms in a rigorous way.
    - These axioms are what we will use in this course.

Conclusion

- Ramon stressed that if you ever feel lost in the course, try to go back to basic, intuitive, common sense ideas. They may not be rigorous, but typically probability theory is just capturing something that you intuitively understand.
- (Paraphrase) "Never lose sight that what we are trying to do is formalize intuition."
- The main thing he wants us to learn is to think probabilistically.


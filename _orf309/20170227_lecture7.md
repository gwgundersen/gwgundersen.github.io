---
title: Independence and conditioning
number: 7
layout: orf309
date: 2017-02-24
---

# Expectation of independent variables

> **Definition.** Let $X$, $Y$ be discrete random variables. $X$ and $Y$ are said to be independent, denoted $X \independent Y$, if:
>
> $$
> \mathbb{P}(\{X=x|Y=y\}) = \mathbb{P}(\{X=x\})
> $$
>
> For all $x, y$.

In words: knowledge of $Y$ does not influence what we know about $X$.

$$
\iff \mathbb{P}(\{X=x, Y=y\}) = \mathbb{P}(\{X=x\}) \mathbb{P}(\{Y=y\})
$$

Independence is typically a **modeling assumption**.

### Example

Throw two fair dice independently. So every outcome between $1, ..., 6$ is equally likely.

**Question:** What is the expected product of the outcomes?

$$
\begin{align}
X &= \{\text{Outcome of die } 1\}\\
Y &= \{\text{Outcome of die } 2\}
\end{align}
$$

Assumption: $X \independent Y$ and $X$, $Y$ are uniformly distributed on $\\{1,2,...,6\\}$

#### Remark: i.i.d.

We say that two random variables are **i.i.d** if they are **independent and identically distributed**. This means that they are independent of each other and come from the same distribution, e.g. two i.i.d. coin tosses are independent and come from a Bernoulli distribution with the same bias.

Compute: $\mathbb{E}(X,Y) = \phi(x,y) = xy$

$$
\begin{align}
\mathbb{E}(X,Y) &= \sum_{x,y=1}^{6} xy \mathbb{P}(\{X=x, Y=y\})\\
&\stackrel{\text{Indep}}{=} \sum_{x,y=1}^{6} \mathbb{P}(\{X=x\})\mathbb{P}(\{Y=y\})\\
&= \sum_{x=1}^{6} x \mathbb{P}(\{X=x\}) \cdot \sum_{y=1}^{6} y \mathbb{P}(\{Y=y\})\\
&= \mathbb{E}(X) \cdot \mathbb{E}(Y) \leftarrow \text{In general not true. Only if $X$, $Y$ are independent}\\
&=3.5^2
\end{align}
$$

### More generally

If $X \independent Y$:

$$
\mathbb{E}(f(x)g(y)) = \mathbb{E}(f(x)) \cdot \mathbb{E}(g(y))
$$

# Conditional expectation

> **Definition.** If $X$, $Y$ are discrete random variables:
>
> $$
> X: \Omega \rightarrow D
> $$
>
> $$
> Y: \Omega \rightarrow D^{\prime}
> $$
>
> The conditional expectation is:
>
> $$
> \mathbb{E}(\phi(X)|Y=y) = \sum_{x \in D} \phi(x) \mathbb{P}(\{X=x, Y=y\})
> $$

In words: just take experiments in which $Y=y$ and compute the expectation over them.

### Example

Repeatedly and independently throw a fair die until the first time we throw a $6$.

**Question.** What is the expected number of $1$s that we throw given that the game ends in the $k$th throw?

$$
\begin{align}
Z_i &= \text{Outcome of $i$th throw}\\
T &= \text{First time we throw a $6$}\\
X &= \text{Total number of $1$s}
\end{align}
$$

**Modeling assumption:** $Z_i$s are **i.i.d.**, uniformly distributed in $\\{1,...,6\\}$

**Compute:** $\mathbb{E}(X\|T=k)$

The total number of $1$s thrown is:

$$
X = \sum_{i=1}^{T-1} \mathbb{1}_{\{Z_i = 1\}}
$$

We do not consider time $T$ because at that point we throw a $6$.

$$
\mathbb{E}(\sum_{i=1}^{T-1} \mathbb{1}_{\{Z_i=1\}} | T=k) = \text{ ?}
$$

$T$ is a random variable. But when $T=k$, it is no longer random.

$$
\begin{align}
&= \mathbb{E}(\sum_{i=1}^{k-1} \mathbb{1}_{\{Z_i=1\}} | T=k) \leftarrow \text{Now we have a non-random sum} \\
&= \sum_{i=1}^{k-1} \mathbb{E}(\mathbb{1}_{\{Z_i=1\}} | T=k) \leftarrow (*) \\
&= \sum_{i=1}^{k-1} \mathbb{P}(\{Z_i = 1 | T=k\}) \\
&= \sum_{i=1}^{k-1} \frac{\mathbb{P}(\{Z_i=1, T=k\})}{\mathbb{P}(\{T=k\})}


\end{align}
$$

<span style="color: red;">($*$) I do not understand why this step is allowed. How come we can just pull out the summation?</span>

Now let's reason about the events and probabilities.

$$
\{T=k\} = \{Z_i \neq 6, Z_2 \neq 6, ..., Z_{k-1} \neq 6, Z_k = 6\}
$$

We know that $Z_i$ are independent events, therefore:

$$
\mathbb{P}(\{T=k\}) \stackrel{Indep}{=} \mathbb{P}(\{Z_i \neq 6\}) \mathbb{P}(\{Z_2 \neq 6\}), ..., \mathbb{P}(\{Z_{k-1} \neq 6\}), \mathbb{P}(\{Z_k = 6\})
$$

And:

$$
\{Z_1, T=k\} = \{Z_1 = 1, Z_2 \neq 6, Z_{k-1} \neq 6, Z_k = 6\}
$$

$$
\mathbb{P}(\{Z_1, T=k\}) = \mathbb{P}(\{Z_1 = 1\}) \mathbb{P}(\{Z_2 \neq 6\}) \mathbb{P}(\{Z_{k-1} \neq 6\}) \mathbb{P}(\{Z_k = 6\})
$$

Notice that the terms cancel!

$$
\frac{\mathbb{P}(\{Z_i=1, T=k\})}{\mathbb{P}(\{T=k\})}
= \frac{\mathbb{P}(\{Z_1 = 1\})}{\mathbb{P}(\{Z_i \neq 6\})}
= \frac{\frac{1}{6}}{\frac{5}{6}}
= \frac{1}{5}
$$

This makes sense. Since we have not thrown a $6$, there are only 5 possible options left.

**Question:** What about $\mathbb{P}(\{Z_i=1 \| T=k\}) = \frac{1}{5}$

$$
\sum_{i=1}^{k-1} \mathbb{P}(\{Z_i=1|T=k\}) = \frac{k-1}{5}
$$

# Conditional distribution

> **Definition.** The conditional distribution of $X$ given $Y$ for discrete random variables is given by:
>
> $$
> (\mathbb{P}(\{X=x|Y=y\}))_{x,y}
> $$

### Tower property

First, remember:

$$
\mathbb{E}(\phi(X) | Y=y) = \sum_{x \in D} \phi(x) \mathbb{P}(\{X=x|Y=y\})
$$

We can say:

$$
\begin{align}
\mathbb{E}(\phi(X)) &= \sum_{x \in D} \phi(x) \mathbb{P}(\{X=x\})\\
&= \sum_{x \in D, y \in D^{\prime}} \phi(x) \mathbb{P}(\{X=x, Y=y\})
\end{align}
$$

Because $\phi$ doesn't depend on $Y$.

$$
\begin{align}
&= \sum_{x \in D, y \in D^{\prime}} \phi(x) \mathbb{P}(\{X=x | Y=y\}) \mathbb{P}(\{Y=y\})\\
&= \sum_{y \in D^{\prime}} \mathbb{E}(\phi(X) | Y=y) \mathbb{P}(\{Y=y\})
\end{align}
$$

This is an important fact. Called the **tower property of conditional expectation**, and it is completely analogous to marginalization.

Just to be clear, the tower property is:

$$
\mathbb{E}(\phi(X)) = \sum_{y \in D^{\prime}} \mathbb{E}(\phi(X) | Y=y) \mathbb{P}(\{Y=y\})
$$

### Example

Problem

- You go to the supermarket, and there are two checkout lines
- You go into one of the lines with equal probability
- The first line has an expected length $\mu$
- The second line has an expected length $\nu$

**Question:** How long is your line on average?

$$
\begin{align}
X &= \text{Line you choose from $\\{1,2\\}$}\\
L &= \text{Length of line}
\end{align}
$$

Modeling assumption: $X$ is uniformly distributed in $\\{1,2\\}$. And:

$$
\begin{align}
\mathbb{E}(L|X=1) &= \mu\\
\mathbb{E}(L|X=2) &= \nu\\
\end{align}
$$

We want to compute $\mathbb{E}(L)$. How to do this? Use the tower property:

$$
\begin{align}
\mathbb{E}(L) &= \mathbb{E}(L|X=1) \mathbb{P}(\{X=1\}) + \mathbb{E}(L|X=2) \mathbb{P}(\{X=2\})\\
&= \mu \frac{1}{2} + \nu \frac{1}{2}\\
&= \frac{\mu + \nu}{2}
\end{align}
$$
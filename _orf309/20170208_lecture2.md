---
title: Lecture 2 - Basic principles of probability
layout: default
---

# Lecture 2: Basic principles of probability

1. Sample Space
2. Events
3. Probability

## 1. Sample Space

> The sample space $\Omega$ is the set of all possible outcomes of random experiments.

- Intuitively, you don't know the result of a dice roll, but you do know the possible outcomes, i.e. 1, 2, 3, 4, 5, or 6.
- We write $\omega \in \Omega$ for a subset of outcomes

#### Examples

1. Throw two dice, one black (i) and one orange (j).

    $$
    \Omega = \{(i,j)\,s.t.\,1 \leq i \leq 6, 1 \leq j \leq 6\}
    $$

2. You are waiting for a bus; you arrived at time 0.

    $$
    \Omega = [0, \infty)
    $$

    - In words, the bus can come any time in the future.

3. The first 5 seconds of a car race.

    $$
    \Omega = \{\forall f: [0,5] \rightarrow [0, \infty)\}
    $$

- Graphically:

<img src="{{ site.url }}/images/orf309/race.png" alt="Plot of racecar speed as a function of time." style="width: 300px;"/>

- In words, the **whole path** of a graph is a single outcome

## 2. Events

- Informal definition: an **event** is a statement whose truthness or falseness can be determined after we perform an experiment.

#### Examples

1. "The sum of the two die is 7."

    Formally, the statement is true if:

    $$
    \omega = \{(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\}
    $$

    Notice that $\omega \subset \Omega$.

2. Car race example (again): "The speed of the car did not exceed 200 mph in the first 2 seconds."

    This is true if and only if:

    $$
    \omega = \{f: f(t) \leq 200\,\forall t\,\leq 2\}
    $$

#### Formal definition

> An event $A$ is a subset $A \subset \omega$

Notice that this is mathematically well-defined. A subtle point:

$$
(1,6) \in \Omega
$$

$$
\{(1,6)\} \subset \Omega
$$

In the first case, an outcome is an element in the set of possible outcomes $\Omega$. In the second case, an event is a subset of possible outcomes. Explicitly, an event is not the same thing as an outcome.

#### Calculus of events

For the following, let A and B be events:

1. $A \cap B$

    <img src="{{ site.url }}/images/orf309/intersection.png" alt="A intersect B." style="width: 300px;"/>

    - The set of all possible outcomes for which both events are true.
    - In English, this is just "and".

2. $A \cup B$

    <img src="{{ site.url }}/images/orf309/union.png" alt="A union B." style="width: 300px;"/>

    - So $A \cup B$ is when $A$ happens or $B$ happens or both.

3. $A^C = \Omega \setminus A$

    <img src="{{ site.url }}/images/orf309/negation.png" alt="A without B." style="width: 300px;"/>

Key point: Now we can **compose** events mathematically.

## 3. Probability

Informally:

> To every event $A$, we assign a number $P(A)$ called its **probability** that describes our degree of confidence that the event will happen.

- To observe that this is vague. "Degree of confidence" is philosophical.
- But there are two extremes we can say something concretely about:
    - If $P(A) = 1$, we are 100% sure that $A$ will happen.
    - If $P(A) = 0$, we are 0% sure that $A$ will happen.

Formally:

> A **probability measure** is an assignment of a number $P(A)$ to every event $A$ such that:
>
> 1. $0 \leq P(A) \leq 1$
> 2. $P(\Omega) = 1$
> 3. Let $A$, $B$ be events such that $A \cap B = \emptyset$. In words, the events are _mutually exclusive_. Then $P(A \cup B) = P(A) + P(B)$. More generally, if $A_1$, $A_2$, ... are mutually exclusive events, then $P(\bigcup\limits_{i=1}^{\infty} A_i) = \sum_{i=1}^{\infty} P(A_i)$.

The above rules are the ones set down by Kolmogorov.

#### Why these rules are important

- First, what justifies the above definition? It describes reality. Our intuition is that probability is a fraction, the number of times an event happens over the number of all events that occurred. But our intuition is **not the definition**. Rather, it is a consequence.
    - Why was the example during the last class period ambiguous? Because the definition of probability was ambiguous. A "fraction" is simply not specific enough. We needed a mathematical formulation.
- Also, we can prove theorems that explain other intuitions. For example:

    - Let $A \subset B$. In English, we can say, "A implies B." If an event $A$ occurs, then an event $B$ must also occur. Our intuition is that the probability of $B$ must be greater than or equal to the probability of $A$. That's because $B$ might occur on its own as well. But we can prove this:

    - Define $B = A \cup B \setminus A$. The events $A$ and $B \setminus A$ are mutually exclusive by definition. They are also consistent with our formulation of the problem: $B$ contains both $A$ and everything that is in $B$ but not in $A$. So by rule 3:

    $$
    P(B) = P(A) + P(B \setminus A)
    $$

    And by rule 1:

    $$
    P(A) + P(B \setminus A) \leq P(A)
    $$

    - Therefore, we have a new fact that aligns with our intuition:

    $$
    P(B) \leq P(A)
    $$

